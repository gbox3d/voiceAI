import pyaudio #pip install pyaudio
import wave
import numpy as np
import webrtcvad # pip install webrtcvad
import struct
import time
from datetime import datetime
import os
from scipy.fftpack import fft
import json


class VoiceDetector:
    """ìŒì„± ê°ì§€ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    # ê¸°ë³¸ ì„¤ì •ê°’ (í´ë˜ìŠ¤ ìƒìˆ˜)
    DEFAULT_SETTINGS = {
        # VAD ë° ê°ì§€ ì„¤ì •
        "vad_mode": 0,                 # VAD ê°ë„ (0: ë‚®ìŒ ~ 3: ë†’ìŒ)
        "voice_threshold": 300,        # ìŒì„± ê°ì§€ ì„ê³„ê°’
        "required_speech_frames": 3,   # ì—°ì† ê°ì§€ í•„ìš” í”„ë ˆì„ ìˆ˜
        "human_freq_low": 85,          # ì‚¬ëŒ ëª©ì†Œë¦¬ ì£¼íŒŒìˆ˜ í•˜í•œ (Hz)
        "human_freq_high": 255,        # ì‚¬ëŒ ëª©ì†Œë¦¬ ì£¼íŒŒìˆ˜ ìƒí•œ (Hz)
        "smoothing_factor": 0.3,       # RMS ìŠ¤ë¬´ë”© ê³„ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€)
        "use_rms": True,               # RMS ë¶„ì„ ì‚¬ìš© ì—¬ë¶€
        "use_freq": True,              # ì£¼íŒŒìˆ˜ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€
        
        # ì˜¤ë””ì˜¤ ì„¤ì •
        "format": pyaudio.paInt16,     # ì˜¤ë””ì˜¤ í˜•ì‹
        "channels": 1,                 # ì±„ë„ ìˆ˜
        "rate": 16000,                 # ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
        "chunk": 480                   # ì²­í¬ í¬ê¸° (ìƒ˜í”Œ ìˆ˜)
    }
    
    # VAD ì§€ì› ìƒ˜í”Œë§ ë ˆì´íŠ¸
    SUPPORTED_VAD_RATES = [8000, 16000, 32000, 48000]
    
    # ì„¤ì • íŒŒì¼ ê¸°ë³¸ ê²½ë¡œ
    DEFAULT_SETTINGS_PATH = "./temp/voice_detector_settings.json"
    
    
    def __init__(self, debug_mode=False, settings_path=None):
        # ì„¤ì • íŒŒì¼ ê²½ë¡œ
        self.settings_path = settings_path or self.DEFAULT_SETTINGS_PATH
        
        # ìƒíƒœ ë³€ìˆ˜ - debug_modeë¥¼ ë¨¼ì € ì„¤ì •
        self.consecutive_speech = 0
        self.debug_mode = debug_mode
        
        # ìŠ¤ë¬´ë”©ì„ ìœ„í•œ ë³€ìˆ˜
        self.smoothed_rms = 0
        
        # ì„¤ì •ê°’ ì´ˆê¸°í™” (íŒŒì¼ì—ì„œ ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
        self._load_or_init_settings()
        
        # VAD ì„¤ì •
        self.vad = webrtcvad.Vad()
        self.vad.set_mode(self.vad_mode)
        
        # PyAudio ì´ˆê¸°í™” ë° ìŠ¤íŠ¸ë¦¼ (íƒì§€ì—ë§Œ í•„ìš”í•  ê²½ìš° ì‚¬ìš©)
        self.p = None
        self.stream = None
    
    def _load_or_init_settings(self):
        """ì„¤ì • íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"""
        # ê¸°ë³¸ ì„¤ì •ê°’ìœ¼ë¡œ ë¨¼ì € ì´ˆê¸°í™”
        self.vad_mode = self.DEFAULT_SETTINGS["vad_mode"]
        self.VOICE_THRESHOLD = self.DEFAULT_SETTINGS["voice_threshold"]
        self.required_speech_frames = self.DEFAULT_SETTINGS["required_speech_frames"]
        self.human_freq_low = self.DEFAULT_SETTINGS["human_freq_low"]
        self.human_freq_high = self.DEFAULT_SETTINGS["human_freq_high"]
        self.smoothing_factor = self.DEFAULT_SETTINGS["smoothing_factor"]
        self.use_rms = self.DEFAULT_SETTINGS["use_rms"]
        self.use_freq = self.DEFAULT_SETTINGS["use_freq"]
        
        # ì˜¤ë””ì˜¤ ì„¤ì • ì´ˆê¸°í™”
        self.FORMAT = self.DEFAULT_SETTINGS["format"]
        self.CHANNELS = self.DEFAULT_SETTINGS["channels"]
        self.RATE = self.DEFAULT_SETTINGS["rate"]
        self.CHUNK = self.DEFAULT_SETTINGS["chunk"]
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        try:
            self.load_settings(self.settings_path)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì†ìƒë˜ì—ˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if self.debug_mode:
                print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
    
    def get_current_settings(self):
        """í˜„ì¬ ì„¤ì •ê°’ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        return {
            # VAD ë° ê°ì§€ ì„¤ì •
            "vad_mode": self.vad_mode,
            "voice_threshold": self.VOICE_THRESHOLD,
            "required_speech_frames": self.required_speech_frames,
            "human_freq_low": self.human_freq_low,
            "human_freq_high": self.human_freq_high,
            "smoothing_factor": self.smoothing_factor,
            "use_rms": self.use_rms,
            "use_freq": self.use_freq,
            
            # ì˜¤ë””ì˜¤ ì„¤ì •
            "format": self.FORMAT,
            "channels": self.CHANNELS,
            "rate": self.RATE,
            "chunk": self.CHUNK
        }
    
    def apply_settings(self, settings):
        """ì„¤ì •ê°’ ë”•ì…”ë„ˆë¦¬ë¥¼ ì ìš©"""
        # ê° ì„¤ì •ê°’ ì ìš© (ì¡´ì¬í•˜ëŠ” í‚¤ë§Œ)
        # VAD ë° ê°ì§€ ì„¤ì • ì ìš©
        if "vad_mode" in settings:
            self.vad_mode = settings["vad_mode"]
            # VAD ëª¨ë“œ ì¦‰ì‹œ ì ìš©
            if hasattr(self, 'vad'):
                self.vad.set_mode(self.vad_mode)
        
        if "voice_threshold" in settings:
            self.VOICE_THRESHOLD = settings["voice_threshold"]
        
        if "required_speech_frames" in settings:
            self.required_speech_frames = settings["required_speech_frames"]
        
        if "human_freq_low" in settings:
            self.human_freq_low = settings["human_freq_low"]
        
        if "human_freq_high" in settings:
            self.human_freq_high = settings["human_freq_high"]
        
        if "smoothing_factor" in settings:
            self.smoothing_factor = settings["smoothing_factor"]
            
        if "use_rms" in settings:
            self.use_rms = settings["use_rms"]
            
        if "use_freq" in settings:
            self.use_freq = settings["use_freq"]
        
        # ì˜¤ë””ì˜¤ ì„¤ì • ì ìš©
        audio_settings_changed = False
        
        if "format" in settings:
            self.FORMAT = settings["format"]
            audio_settings_changed = True
        
        if "channels" in settings:
            # print(settings["channels"])
            self.CHANNELS = settings["channels"]
            audio_settings_changed = True
        
        if "rate" in settings:
            # VAD ì§€ì› ìƒ˜í”Œë§ ë ˆì´íŠ¸ì¸ì§€ í™•ì¸
            if settings["rate"] in self.SUPPORTED_VAD_RATES:
                self.RATE = settings["rate"]
                audio_settings_changed = True
            else:
                if self.debug_mode:
                    print(f"ê²½ê³ : {settings['rate']}HzëŠ” WebRTC VADê°€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§€ì› ë ˆì´íŠ¸: {self.SUPPORTED_VAD_RATES}")
        
        if "chunk" in settings:
            self.CHUNK = settings["chunk"]
            audio_settings_changed = True
        
        # ì˜¤ë””ì˜¤ ì„¤ì •ì´ ë³€ê²½ëœ ê²½ìš° ìŠ¤íŠ¸ë¦¼ ì¬ì´ˆê¸°í™”
        if audio_settings_changed and self.stream is not None:
            self._reinitialize_stream()
            
        return audio_settings_changed
    
    def _reinitialize_stream(self):
        """ì˜¤ë””ì˜¤ ì„¤ì • ë³€ê²½ í›„ ìŠ¤íŠ¸ë¦¼ ì¬ì´ˆê¸°í™”"""
        # í˜„ì¬ ì¥ì¹˜ ì¸ë±ìŠ¤ ì €ì¥
        device_index = None
        if hasattr(self.stream, '_device_index'):
            device_index = self.stream._device_index
            
        # ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
        self.stream.stop_stream()
        self.stream.close()
        
        # ìƒˆ ì„¤ì •ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ ì¬ìƒì„±
        self.stream = self.p.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=self.CHUNK
        )
        
        if self.debug_mode:
            print(f"ì˜¤ë””ì˜¤ ì„¤ì • ë³€ê²½ë¨: ë ˆì´íŠ¸={self.RATE}Hz, ì²­í¬={self.CHUNK}")
    
    def save_settings(self, file_path=None):
        """í˜„ì¬ ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥"""
        # ê²½ë¡œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        file_path = file_path or self.settings_path
        
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        settings = self.get_current_settings()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(settings, f, indent=4)
            
            if self.debug_mode:
                print(f"ì„¤ì •ì´ '{file_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            if self.debug_mode:
                print(f"ì„¤ì • ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def load_settings(self, file_path=None):
        """íŒŒì¼ì—ì„œ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°"""
        # ê²½ë¡œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        file_path = file_path or self.settings_path
        
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(file_path):
                if self.debug_mode:
                    print(f"ì„¤ì • íŒŒì¼ '{file_path}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return False
            
            # JSON íŒŒì¼ ë¡œë“œ
            with open(file_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            
            # ì„¤ì • ì ìš©
            self.apply_settings(settings)
            
            if self.debug_mode:
                print(f"'{file_path}'ì—ì„œ ì„¤ì •ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            if self.debug_mode:
                print(f"ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def reset_to_defaults(self):
        """ì„¤ì •ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self.apply_settings(self.DEFAULT_SETTINGS)
        if self.debug_mode:
            print("ì„¤ì •ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    
    def initialize_stream(self, device_index=None):
        """í•„ìš”í•œ ê²½ìš° ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” (íŠ¹ì • ì¥ì¹˜ ì„ íƒ ê°€ëŠ¥)"""
        if self.p is None:
            self.p = pyaudio.PyAudio()
        
        if self.stream is None:
            self.stream = self.p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                input_device_index=device_index,  # ì„ íƒëœ ì¥ì¹˜ ì¸ë±ìŠ¤ ì‚¬ìš©
                frames_per_buffer=self.CHUNK
            )
            # ì¥ì¹˜ ì¸ë±ìŠ¤ ì €ì¥ (ë‚˜ì¤‘ì— ì¬ì´ˆê¸°í™”í•  ë•Œ ì‚¬ìš©)
            if device_index is not None:
                self.stream._device_index = device_index
    
    
    def get_audio_devices(self):
        """ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ëª©ë¡ ë°˜í™˜"""
        if self.p is None:
            self.p = pyaudio.PyAudio()
        
        devices = []
        info = []
        
        # ëª¨ë“  ì¥ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        for i in range(self.p.get_device_count()):
            device_info = self.p.get_device_info_by_index(i)
            # ì…ë ¥ ì±„ë„ì´ ìˆëŠ” ì¥ì¹˜ë§Œ ì„ íƒ (ë§ˆì´í¬)
            if device_info['maxInputChannels'] > 0:
                name = device_info['name']
                devices.append(f"{i}: {name}")
                info.append({
                    'index': i,
                    'name': name,
                    'channels': device_info['maxInputChannels'],
                    'sample_rate': int(device_info['defaultSampleRate'])
                })
        
        return devices, info
    
    def close_stream(self):
        """ìŠ¤íŠ¸ë¦¼ ë° PyAudio ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.stream is not None:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        
        if self.p is not None:
            self.p.terminate()
            self.p = None
    
    def calibrate(self):
        """ì£¼ë³€ í™˜ê²½ ì†ŒìŒì„ ì¸¡ì •í•˜ì—¬ ì„ê³„ê°’ ìë™ ì¡°ì •"""
        print("í™˜ê²½ ì†ŒìŒ ì¸¡ì • ì¤‘... (10ì´ˆ)")
        
        # í•„ìš”í•œ ê²½ìš° ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
        self.initialize_stream()
        
        samples = []
        
        # 10ì´ˆ ë™ì•ˆ ìƒ˜í”Œ ìˆ˜ì§‘ (5ì´ˆì—ì„œ 10ì´ˆë¡œ ì¦ê°€)
        for _ in range(int(self.RATE / self.CHUNK * 10)):
            audio_data = self.stream.read(self.CHUNK, exception_on_overflow=False)
            rms = self.get_rms(audio_data)
            samples.append(rms)
        
        # ë°°ê²½ ì†ŒìŒ ë ˆë²¨ ê³„ì‚° (í•˜ìœ„ 80%ì˜ í‰ê·  ì‚¬ìš©)
        samples.sort()
        valid_samples = samples[:int(len(samples) * 0.8)]  # ìƒìœ„ 20% ì œì™¸ (ì¼ì‹œì  ì†ŒìŒ ì œê±°)
        background_noise = np.mean(valid_samples)
        noise_std = np.std(valid_samples)
        
        # ì„ê³„ê°’ ì„¤ì • (ë°°ê²½ ì†ŒìŒ + í‘œì¤€í¸ì°¨ì˜ 4ë°°)
        self.VOICE_THRESHOLD = background_noise + noise_std * 4.0
        
        print(f"ì¸¡ì • ì™„ë£Œ. ë°°ê²½ ì†ŒìŒ ë ˆë²¨: {background_noise:.2f}")
        print(f"ìŒì„± ê°ì§€ ì„ê³„ê°’: {self.VOICE_THRESHOLD:.2f}ë¡œ ì„¤ì •ë¨")
    
    def detect_speech(self, audio_data):
        """ê°œì„ ëœ ìŒì„± ê°ì§€ ë¡œì§ - ë‚´ë¶€ ì„¤ì • ì‚¬ìš©
        
        Args:
            audio_data: ë¶„ì„í•  ì˜¤ë””ì˜¤ ë°ì´í„°
            
        Returns:
            tuple: (speech_detected, vad_result, rms_value, rms_result, freq_result)
                - speech_detected: ìµœì¢… ìŒì„± ê°ì§€ ì—¬ë¶€
                - vad_result: VAD ê²°ê³¼
                - rms_value: ê³„ì‚°ëœ RMS ê°’
                - rms_result: RMS ë¶„ì„ ê²°ê³¼
                - freq_result: ì£¼íŒŒìˆ˜ ë¶„ì„ ê²°ê³¼
        """
        # WebRTC VADë¡œ ìŒì„± ê°ì§€ (í•­ìƒ ì‹¤í–‰)
        try:
            vad_result = self.vad.is_speech(audio_data, self.RATE)
        # except:
        #     print("VAD ì˜¤ë¥˜")
        #     vad_result = False
        except Exception as e:
            if self.debug_mode:
                print(f"VAD ì˜¤ë¥˜: {e}")
            vad_result = False
        
        # RMS ê¸°ë°˜ ê°ì§€ (ì„ íƒì  ì‹¤í–‰)
        rms = self.get_rms(audio_data)
        self.smoothed_rms = self.smoothing_factor * rms + (1 - self.smoothing_factor) * self.smoothed_rms
        rms_result = self.smoothed_rms > self.VOICE_THRESHOLD if self.use_rms else False
        
        # ì£¼íŒŒìˆ˜ ë¶„ì„ ê¸°ë°˜ ê°ì§€ (ì„ íƒì  ì‹¤í–‰)
        if self.use_freq:
            freq_result = self.check_human_freq(audio_data)
        else:
            freq_result = False
        
        # ë””ë²„ê·¸ ëª¨ë“œì—ì„œëŠ” ìƒì„¸ ì •ë³´ ì¶œë ¥
        if self.debug_mode:
            # ê° ì¡°ê±´ë³„ ì•„ì´ì½˜ í‘œì‹œ
            vad_icon = "âœ“" if vad_result else "âœ—"
            rms_icon = "âœ“" if rms_result else "âœ—"
            freq_icon = "âœ“" if freq_result else "âœ—"
            
            # ìµœì¢… ê²°ì • ë¡œì§ (ì„ íƒì— ë”°ë¼ ë‹¤ë¦„)
            if self.use_rms and self.use_freq:
                speech = "ğŸ—£ï¸" if (vad_result and (rms_result or freq_result)) else "  "
            elif self.use_rms:
                speech = "ğŸ—£ï¸" if (vad_result and rms_result) else "  "
            elif self.use_freq:
                speech = "ğŸ—£ï¸" if (vad_result and freq_result) else "  "
            else:
                speech = "ğŸ—£ï¸" if vad_result else "  "
            
            # ë””ë²„ê·¸ ì •ë³´ ìƒì„¸ ì¶œë ¥
            print(f"VAD: {vad_icon}, RMS: {rms_icon}({self.smoothed_rms:.1f}/{self.VOICE_THRESHOLD:.1f}), FREQ: {freq_icon} {speech}", end='\r')
        
        # ìµœì¢… ê²°ê³¼ ê²°ì • (ì„ íƒì— ë”°ë¼ ë‹¤ë¦„)
        if self.use_rms and self.use_freq:
            # ë‘˜ ë‹¤ ì‚¬ìš©í•˜ëŠ” ê²½ìš° - í•˜ë‚˜ë¼ë„ Trueë©´ ì¶©ë¶„
            speech_detected = vad_result and (rms_result or freq_result)
        elif self.use_rms:
            # RMSë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
            speech_detected = vad_result and rms_result
        elif self.use_freq:
            # ì£¼íŒŒìˆ˜ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
            speech_detected = vad_result and freq_result
        else:
            # ë‘˜ ë‹¤ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° - VADë¡œë§Œ íŒë‹¨
            speech_detected = vad_result
        
        # ì—°ì†ì ì¸ ìŒì„± í”„ë ˆì„ ì¹´ìš´íŒ… ë° ê´€ë¦¬
        if speech_detected:
            self.consecutive_speech += 1
        else:
            self.consecutive_speech = 0
        
        # ê²°ê³¼ ë°˜í™˜
        return speech_detected, vad_result, self.smoothed_rms, rms_result, freq_result
    
    def is_speech_continuous(self):
        """ì§€ì •ëœ ì—°ì† í”„ë ˆì„ ì´ìƒ ìŒì„±ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.consecutive_speech >= self.required_speech_frames
    
    def check_human_freq(self, audio_data):
        """ì‚¬ëŒ ëª©ì†Œë¦¬ ì£¼íŒŒìˆ˜ ëŒ€ì—­ í™•ì¸"""
        try:
            # ë°ì´í„°ë¥¼ float32ë¡œ ë³€í™˜
            count = len(audio_data) // 2
            format_str = "%dh" % count
            shorts = struct.unpack(format_str, audio_data)
            data = np.array(shorts).astype(np.float32) / 32768.0  # ì •ê·œí™”
            
            # FFT ìˆ˜í–‰
            fft_data = fft(data)
            # ì£¼íŒŒìˆ˜ ì„±ë¶„ ê³„ì‚°
            fft_freqs = np.fft.fftfreq(len(data), 1.0/self.RATE)
            
            # ì‚¬ëŒ ëª©ì†Œë¦¬ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì˜ íŒŒì›Œ ê³„ì‚°
            voice_freq_mask = (fft_freqs >= self.human_freq_low) & (fft_freqs <= self.human_freq_high)
            all_freq_power = np.sum(np.abs(fft_data))
            
            if all_freq_power == 0:
                return False
                
            voice_freq_power = np.sum(np.abs(fft_data[voice_freq_mask]))
            voice_power_ratio = voice_freq_power / all_freq_power
            
            # ì‚¬ëŒ ëª©ì†Œë¦¬ ëŒ€ì—­ì˜ íŒŒì›Œê°€ ì „ì²´ì˜ 10% ì´ìƒì´ë©´ ì‚¬ëŒ ëª©ì†Œë¦¬ë¡œ íŒë‹¨ (20% â†’ 10%ë¡œ ì™„í™”)
            return voice_power_ratio > 0.1
            
        except Exception as e:
            if self.debug_mode:
                print(f"ì£¼íŒŒìˆ˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return True  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ True ë°˜í™˜
    
    def get_rms(self, audio_data):
        """ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ RMS(Root Mean Square) ê°’ ê³„ì‚°"""
        count = len(audio_data) // 2
        format_str = "%dh" % count
        try:
            shorts = struct.unpack(format_str, audio_data)
            shorts_array = np.array(shorts).astype(np.float32)
            sum_squares = np.sum(shorts_array ** 2)
            rms = np.sqrt(max(0, sum_squares / count))
            return rms
        except Exception as e:
            if self.debug_mode:
                print(f"RMS ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0
    
    def get_format_name(self, format_value):
        """í¬ë§· ê°’ì„ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        format_names = {
            pyaudio.paInt8: "8-bit Integer",
            pyaudio.paInt16: "16-bit Integer",
            pyaudio.paInt24: "24-bit Integer",
            pyaudio.paInt32: "32-bit Integer",
            pyaudio.paFloat32: "32-bit Float"
        }
        return format_names.get(format_value, f"Unknown ({format_value})")
    
    def get_audio_settings_summary(self):
        """í˜„ì¬ ì˜¤ë””ì˜¤ ì„¤ì • ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return {
            "format": self.get_format_name(self.FORMAT),
            "channels": self.CHANNELS,
            "rate": f"{self.RATE} Hz",
            "chunk": f"{self.CHUNK} samples ({self.CHUNK / self.RATE * 1000:.1f} ms)"
        }

        
        
    
# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì„¤ì •
    detector = VoiceDetector(debug_mode=True)
    
    # ì˜¤ë””ì˜¤ ì„¤ì • ìš”ì•½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    audio_settings = detector.get_audio_settings_summary()
    
    # ëª¨ë“  ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    all_settings = detector.get_current_settings()
    
    # ì¶œë ¥
    print("===== ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ì •ë³´ =====")
    print(f"í¬ë§·: {audio_settings['format']}")
    print(f"ì±„ë„: {audio_settings['channels']}")
    print(f"ìƒ˜í”Œë§ ë ˆì´íŠ¸: {audio_settings['rate']}")
    print(f"ì²­í¬ í¬ê¸°: {audio_settings['chunk']}")
    
    print("\n===== VAD ê´€ë ¨ ì„¤ì • =====")
    print(f"VAD ëª¨ë“œ: {all_settings['vad_mode']} (0: ë‚®ìŒ ~ 3: ë†’ìŒ)")
    print(f"VAD ì§€ì› ìƒ˜í”Œë§ ë ˆì´íŠ¸: {detector.SUPPORTED_VAD_RATES}")
    
    # í”„ë ˆì„ í¬ê¸° ê²€ì¦ (VAD í˜¸í™˜ì„±)
    chunk_samples = detector.CHUNK
    chunk_ms = (chunk_samples * 1000) / detector.RATE
    
    print(f"\ní˜„ì¬ ì²­í¬ í¬ê¸°: {chunk_samples} ìƒ˜í”Œ ({chunk_ms:.1f}ms)")
    
    # VAD ìœ íš¨ í”„ë ˆì„ í¬ê¸° (16kHz ê¸°ì¤€)
    valid_ms = [10, 20, 30]
    valid_samples = [detector.RATE // 100, detector.RATE // 50, detector.RATE // 33]
    
    print("VAD ìœ íš¨ í”„ë ˆì„ í¬ê¸°:")
    for ms, samples in zip(valid_ms, valid_samples):
        print(f"- {ms}ms = {samples} ìƒ˜í”Œ")
    
    # í˜„ì¬ ì„¤ì •ì´ ìœ íš¨í•œì§€ í™•ì¸
    if chunk_samples in valid_samples:
        print(f"\ní˜„ì¬ ì²­í¬ í¬ê¸° {chunk_samples}ëŠ” VADì— ìœ íš¨í•©ë‹ˆë‹¤.")
    else:
        print(f"\nê²½ê³ : í˜„ì¬ ì²­í¬ í¬ê¸° {chunk_samples}ëŠ” VADì— ìœ íš¨í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("VADëŠ” 10ms, 20ms, 30ms í”„ë ˆì„ ê¸¸ì´ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
     
    # ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” (ê¸°ë³¸ ë§ˆì´í¬ ì‚¬ìš©)
    detector.initialize_stream()
    
    print("VAD í…ŒìŠ¤íŠ¸ ì‹œì‘... Ctrl+Cë¡œ ì¢…ë£Œ")
    
    try:
        while True:
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
            audio_data = detector.stream.read(detector.CHUNK, exception_on_overflow=False)
            
            # ìŒì„± ê°ì§€ (ë””ë²„ê·¸ ì¶œë ¥ ìë™ìœ¼ë¡œ í‘œì‹œë¨)
            detector.detect_speech(audio_data)
            
            # CPU ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸°
            time.sleep(0.01)
    
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ ì¢…ë£Œ")
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        detector.close_stream()